{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\keras\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import keras\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# import keras_metrics\n",
    "\n",
    "from keras.applications import mobilenet, resnet50 #, vgg16, inception_v3, resnet50, \n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, History\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "import logging\n",
    "# logging.getLogger().setLevel(logging.DEBUG)\n",
    "import pickle\n",
    "\n",
    "\n",
    "import seaborn\n",
    "seaborn.set_style(\"darkgrid\")\n",
    "\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_dir = 'E:\\\\Work/PathoBarIlan/Shlomi2018/'\n",
    "# all_data_dir = '/media/leetwito/DATA/Datasets/PathoBarIlan/Shlomi2018'\n",
    "\n",
    "is_relative_path_csv = False\n",
    "seed = 4221\n",
    "\n",
    "pos_name_init = 'Cancer'\n",
    "neg_name_init = 'Normal'\n",
    "\n",
    "use_rgb = True # True=rgb, False=spectral\n",
    "if use_rgb:\n",
    "    file_ext = '.png'\n",
    "else:\n",
    "    file_ext = '.npy'\n",
    "    \n",
    "window_size = (200, 200)\n",
    "shift = (100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h = window_size\n",
    "if use_rgb:\n",
    "    input_shape = (w,h,3)\n",
    "else:\n",
    "    input_shape = (w,h,40)\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/leetwito/Windows/Users/leetw/PycharmProjects/PathoBarIlan/my_models/k=2, lr5e-4/losses.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-fcc38e939298>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/media/leetwito/Windows/Users/leetw/PycharmProjects/PathoBarIlan/my_models/k=2, lr5e-4/losses.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/leetwito/Windows/Users/leetw/PycharmProjects/PathoBarIlan/my_models/k=2, lr5e-4/losses.txt'"
     ]
    }
   ],
   "source": [
    "path = '/media/leetwito/Windows/Users/leetw/PycharmProjects/PathoBarIlan/my_models/k=2, lr5e-4/losses.txt'\n",
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-5174024fba07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#     line = str(line)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lines' is not defined"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "for line in lines:\n",
    "#     line = str(line)\n",
    "    train_loss.append(float(line.split(\":\")[2][:-1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_, _, val_loss = pickle.load(open(\"/media/leetwito/Windows/Users/leetw/PycharmProjects/PathoBarIlan/my_models/k=2, lr5e-4/model_spec_weights_epoch238-val_loss0.013-seed4221-k_idx=2-[y_gt,y_proba,loss]-val.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e77abb2fda29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfile_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/media/leetwito/Windows/Users/leetw/PycharmProjects/PathoBarIlan/my_models/k=2, lr5e-4/*.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "file_names = glob('/media/leetwito/Windows/Users/leetw/PycharmProjects/PathoBarIlan/my_models/k=2, lr5e-4/*.hdf5')\n",
    "i=0\n",
    "int(file_names[i].split(\"epoch\")[1].split(\"-\")[0])\n",
    "file_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "epoch = []\n",
    "for file in file_names:\n",
    "    epoch_num = int(file.split(\"epoch\")[1].split(\"-\")[0])\n",
    "    if epoch_num > 80:\n",
    "        continue\n",
    "    val.append(float(file.split(\"val_loss\")[1].split(\"-\")[0]))\n",
    "    epoch.append(epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"val_loss\":val, \"epoch\":epoch}).set_index(\"epoch\").sort_index()\n",
    "dff = pd.DataFrame([0] + train_loss, columns=[\"train\"]).iloc[1:]\n",
    "dfff = pd.concat([df, dff], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Empty 'DataFrame': no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-762d48e0ddc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\keras\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[0;32m   2939\u001b[0m                           \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolormap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m                           \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecondary_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2941\u001b[1;33m                           sort_columns=sort_columns, **kwds)\n\u001b[0m\u001b[0;32m   2942\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\keras\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mplot_frame\u001b[1;34m(data, x, y, kind, ax, subplots, sharex, sharey, layout, figsize, use_index, title, grid, legend, style, logx, logy, loglog, xticks, yticks, xlim, ylim, rot, fontsize, colormap, table, yerr, xerr, secondary_y, sort_columns, **kwds)\u001b[0m\n\u001b[0;32m   1975\u001b[0m                  \u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxerr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1976\u001b[0m                  \u001b[0msecondary_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msecondary_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort_columns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1977\u001b[1;33m                  **kwds)\n\u001b[0m\u001b[0;32m   1978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\keras\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m_plot\u001b[1;34m(data, x, y, subplots, ax, kind, **kwds)\u001b[0m\n\u001b[0;32m   1802\u001b[0m         \u001b[0mplot_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubplots\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1804\u001b[1;33m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1805\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\keras\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\keras\\lib\\site-packages\\pandas\\plotting\\_core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m             raise TypeError('Empty {0!r}: no numeric data to '\n\u001b[1;32m--> 373\u001b[1;33m                             'plot'.format(numeric_data.__class__.__name__))\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Empty 'DataFrame': no numeric data to plot"
     ]
    }
   ],
   "source": [
    "dfff.rolling(5).mean().plot(figsize=(15, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders = glob('/media/leetwito/Windows/Users/leetw/PycharmProjects/PathoBarIlan/my_models/k*')\n",
    "folders = glob('my_models/k*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XY():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(n_batches, batch_size, sub, i, XY):\n",
    "#             start = time()\n",
    "    if use_rgb:\n",
    "\n",
    "        X = [img_to_array(load_img(f.replace(\"npy\", \"png\"), target_size=input_shape)) for f in sub.filename]\n",
    "    else:\n",
    "        X = [np.load(f) for f in sub.filename]\n",
    "#             end = time()\n",
    "#             print(\"batch load time: {}\".format(end-start))\n",
    "\n",
    "    X = batch_norm(np.stack(X))\n",
    "    logging.debug(\"from file {}\\nto file {}\".format(sub.iloc[0].filename, sub.iloc[-1].filename))\n",
    "\n",
    "    Y = sub.label.values\n",
    "    Y = to_categorical(Y, num_classes=2)\n",
    "    \n",
    "    XY.X = X\n",
    "    XY.Y = Y\n",
    "    return None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_xy_orig(n_batches, batch_size, sub, i):\n",
    "#             start = time()\n",
    "    if use_rgb:\n",
    "\n",
    "        X = [img_to_array(load_img(f.replace(\"npy\", \"png\"), target_size=input_shape)) for f in sub.filename]\n",
    "    else:\n",
    "        X = [np.load(f) for f in sub.filename]\n",
    "#             end = time()\n",
    "#             print(\"batch load time: {}\".format(end-start))\n",
    "\n",
    "    X = batch_norm(np.stack(X))\n",
    "    logging.debug(\"from file {}\\nto file {}\".format(sub.iloc[0].filename, sub.iloc[-1].filename))\n",
    "\n",
    "    Y = sub.label.values\n",
    "    Y = to_categorical(Y, num_classes=2)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def batch_norm(x):\n",
    "#     print(\"x.shape:\", x.shape)\n",
    "    maxi = x.max(axis=1).max(axis=1)\n",
    "#     print(\"maxi.shape:\", maxi.shape)\n",
    "    maxi = np.repeat(maxi[:, np.newaxis, : ], window_size[0], axis=1)\n",
    "    maxi = np.repeat(maxi[:, np.newaxis, : ], window_size[1], axis=1)\n",
    "    return x/maxi\n",
    "\n",
    "\n",
    "def generator_from_df(df, batch_size, shuffle=True): \n",
    "    \n",
    "    n_batches = df.shape[0]//batch_size\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            df_tmp = df.copy().sample(frac=1)  # frac=1 is same as shuffling df.\n",
    "        else:\n",
    "            df_tmp = df\n",
    "\n",
    "        for i in range(n_batches):\n",
    "            sub = df_tmp.iloc[batch_size*i:batch_size*(i+1)]\n",
    "            X, Y = get_xy_orig(n_batches, batch_size, sub, i)\n",
    "            # Simple model, one input, one output.\n",
    "\n",
    "            yield X, Y\n",
    "        del df_tmp\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(x):\n",
    "#     print(\"x.shape:\", x.shape)\n",
    "    maxi = x.max(axis=1).max(axis=1)\n",
    "#     print(\"maxi.shape:\", maxi.shape)\n",
    "    maxi = np.repeat(maxi[:, np.newaxis, : ], window_size[0], axis=1)\n",
    "    maxi = np.repeat(maxi[:, np.newaxis, : ], window_size[1], axis=1)\n",
    "    return x/maxi\n",
    "\n",
    "\n",
    "def generator_from_df(df, batch_size, shuffle=True): \n",
    "    \n",
    "    n_batches = df.shape[0]//batch_size\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            df_tmp = df.copy().sample(frac=1)  # frac=1 is same as shuffling df.\n",
    "        else:\n",
    "            df_tmp = df\n",
    "\n",
    "        xy = XY()\n",
    "        for i in range(n_batches):\n",
    "            if i==0:\n",
    "                sub = df_tmp.iloc[batch_size*i:batch_size*(i+1)]\n",
    "                xy_tmp = XY()\n",
    "                get_xy(n_batches, batch_size, sub, i, xy_tmp)\n",
    "            j = i+1\n",
    "            sub = df_tmp.iloc[batch_size*j:batch_size*(j+1)]\n",
    "            t = threading.Thread(target=get_xy, args=(n_batches, batch_size, sub, j, xy))\n",
    "            t.start()\n",
    "            # Simple model, one input, one output.\n",
    "            if i==0:\n",
    "                yield xy_tmp.X, xy_tmp.Y\n",
    "            else:\n",
    "                yield xy.X, xy.Y\n",
    "#                 print(\"after yield.\")\n",
    "                t.join()\n",
    "\n",
    "        del df_tmp\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_test_and_pred():\n",
    "    y_tests = []\n",
    "    y_preds = []\n",
    "    for i in range(len(df_test)//batch_size):\n",
    "        print(i, \"out of\", len(df_test)//batch_size)\n",
    "        x, y = next(test_generator)\n",
    "        print(mobilenet_model.evaluate(x, y))\n",
    "        y_tests.append(y.argmax(axis=1))\n",
    "        y_preds.append(mobilenet_model.predict(x)[:,1])\n",
    "    \n",
    "    y_test = np.stack(y_tests)\n",
    "    y_pred = np.stack(y_preds)\n",
    "\n",
    "    y_test = y_test.reshape((-1, 1))\n",
    "    y_pred = y_pred.reshape((-1, 1))\n",
    "    \n",
    "    return y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_val = (float(model.split(\"val_loss\")[1].split(\"-\")[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_models\\\\k_0\\\\model_rgb_weights_epoch99-val_loss0.003.hdf5'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = glob('my_models/k*')\n",
    "all_ckpnts = glob(folders[0]+\"/*.hdf5\")\n",
    "all_ckpnts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet_model = keras.models.load_model(all_ckpnts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model = mobilenet.MobileNet(include_top=True, weights=None, input_shape=input_shape, classes=2, dropout=0.2)\n",
    "optimizer = Adam(lr=5e-4) # 1e-3\n",
    "mobilenet_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer) #  binary_crossentropy , categorical_crossentropy\n",
    "\n",
    "mobilenet_model.load_weights(all_ckpnts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 200, 200, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_pickle(\"df_test_%i\"%0)\n",
    "test_generator = generator_from_df(df_test, batch_size, shuffle=False)\n",
    "x, y = next(test_generator)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 55.334858, 200.66524 ], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet_model.predict(x).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from time import time\n",
    "for j in range(5):\n",
    "    tic = time()\n",
    "    for i in range(100):\n",
    "        x, y = next(test_generator)\n",
    "        (mobilenet_model.predict(x).sum(axis=0))\n",
    "    toc = time()\n",
    "    print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(256, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "mobilenet_model.predict(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mobilenet_model = mobilenet.MobileNet(include_top=True, weights=None, input_shape=input_shape, classes=2, dropout=0.2)\n",
    "optimizer = Adam(lr=5e-4) # 1e-3\n",
    "mobilenet_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer) #  binary_crossentropy , categorical_crossentropy\n",
    "y_trues = []\n",
    "y_preds = []\n",
    "\n",
    "\n",
    "for i, folder in enumerate(folders):\n",
    "    print(\"\\n---------------------------------\\n in %d file=%s\\n---------------------------------\"%(i, folder))\n",
    "    df_test = pd.read_pickle(\"df_test_%i\"%i)\n",
    "    test_generator = generator_from_df(df_test, 16, shuffle=False)\n",
    "    all_ckpnts = glob(folder+\"/*.hdf5\")\n",
    "    val = 100\n",
    "    for model in all_ckpnts:\n",
    "        tmp_val = float(model.split(\"val_loss\")[1].split(\".\")[0] + \".\" + model.split(\"val_loss\")[1].split(\".\")[1])\n",
    "        if tmp_val<val:\n",
    "            file = model\n",
    "            val = tmp_val\n",
    "    print(\"read model\")\n",
    "    mobilenet_model.load_weights(file)\n",
    "    y_test, y_pred = get_y_test_and_pred()\n",
    "    y_trues.append(y_test)\n",
    "    y_preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_scores, figsize=(15, 15)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_scores)\n",
    "    \n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    \n",
    "    plt.xlabel('TP rate', fontsize=20)\n",
    "    plt.ylabel('FP rate', fontsize=20)\n",
    "    plt.ylim([0.0, 1.1])\n",
    "    plt.xlim([-0.02, 1.02])\n",
    "    plt.title('RGB: ROC curve: AUC={0:0.3f}'.format(roc_auc_score(y_trues, y_preds)), fontsize=30)\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "        \n",
    "    plt.axes()\n",
    "\n",
    "    return fpr, tpr, threshold\n",
    "\n",
    "def plot_precision_recall_curve(y_true, y_scores, figsize=(15, 8)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    precision, recall, threshold = precision_recall_curve(y_true, y_scores)\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                   if 'step' in signature(plt.fill_between).parameters\n",
    "                   else {})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b')\n",
    "\n",
    "    plt.xlabel('Recall', fontsize=20)\n",
    "    plt.ylabel('Precision', fontsize=20)\n",
    "    plt.ylim([0.0, 1.1])\n",
    "    plt.xlim([0.0, 1.02])\n",
    "    plt.title('RGB: Precision-Recall curve: AP={0:0.3f}'.format(\n",
    "              average_precision), fontsize=30)\n",
    "    plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "    return fpr, tpr, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = [i[:, 0] for i in y_trues] \n",
    "y_preds = [i[:, 0] for i in y_preds] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = np.concatenate(y_trues)\n",
    "y_preds = np.concatenate(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([y_trues, y_preds], open('./my_models/all_y_trues-all_y_preds.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = plot_roc_curve(y_trues, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = plot_precision_recall_curve(y_trues, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold[(precision+recall).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_trues, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_trues>0.5, y_preds>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall_score(y_trues>0.5, y_preds>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = 0.22\n",
    "((y_trues>ts)==(y_preds>ts)).sum()/(y_trues.shape[0]), ((y_trues[y_trues==1]>ts)==(y_preds[y_trues==1]>ts)).sum()/(y_trues[y_trues==1].shape[0]), ((y_trues[y_trues==0]>ts)==(y_preds[y_trues==0]>ts)).sum()/(y_trues[y_trues==0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues[y_trues==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(y_trues, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.utils.fixes import signature\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision = average_precision_score(y_trues, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_trues, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.9, 1.05])\n",
    "plt.xlim([0.9, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "95 + 81 + 1815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1177 + 222 -97 + 222 - 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
